{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/archive_dataset.zip\" -d \"/content/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('/content/dataset/Landscape Classification/Landscape Classification/Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # Resize to fit ResNet50\n",
    "    transforms.ToTensor(),           # Convert images to tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/dataset/Landscape Classification/Landscape Classification/Training Data\"\n",
    "\n",
    "dataset_val_path = \"/content/dataset/Landscape Classification/Landscape Classification/Validation Data\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "dataset_val = datasets.ImageFolder(root=dataset_val_path, transform=transform)\n",
    "\n",
    "# Check class names\n",
    "print(dataset.classes)\n",
    "print(dataset_val.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(dataset)  \n",
    "val_size = len(dataset_val) \n",
    "#train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for our number of classes\n",
    "num_features = model.fc.in_features\n",
    "num_classes = len(dataset.classes)  # Number of labels in your dataset\n",
    "model.fc = torch.nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/resnet50_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/content/drive/MyDrive/resnet50_model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image from local storage\n",
    "image_path = \"/content/drive/MyDrive/glacierimage.webp\"  # Replace with your test image path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Apply the same transformations used during training\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Convert the image\n",
    "input_tensor = image_transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move to GPU if available\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# Predict the class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    predicted_class = torch.argmax(output).item()\n",
    "\n",
    "# Get class labels\n",
    "class_labels = dataset.classes\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "# Show result\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Predicted Label: {predicted_label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/drive/MyDrive/data.csv\")\n",
    "genre_data = pd.read_csv('/content/drive/MyDrive/data_by_genres.csv')\n",
    "year_data = pd.read_csv('/content/drive/MyDrive/data_by_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genre_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(year_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "feature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n",
    "\n",
    "X, y = data[feature_names], data['popularity']\n",
    "\n",
    "# Create a list of the feature names\n",
    "features = np.array(feature_names)\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = FeatureCorrelation(labels=features)\n",
    "\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "visualizer.fit(X, y)     # Fit the data to the visualizer\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade(year):\n",
    "    period_start = int(year/10) * 10\n",
    "    decade = '{}s'.format(period_start)\n",
    "    return decade\n",
    "\n",
    "data['decade'] = data['year'].apply(get_decade)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11 ,6)})\n",
    "sns.countplot(data['decade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'valence']\n",
    "fig = px.line(year_data, x='year', y=sound_features)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_genres = genre_data.nlargest(10, 'popularity')\n",
    "\n",
    "fig = px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'], barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10))])\n",
    "X = genre_data.select_dtypes(np.number)\n",
    "cluster_pipeline.fit(X)\n",
    "genre_data['cluster'] = cluster_pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Clusters with t-SNE\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_pipeline = Pipeline([('scaler', StandardScaler()), ('tsne', TSNE(n_components=2, verbose=1))])\n",
    "genre_embedding = tsne_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding)\n",
    "projection['genres'] = genre_data['genres']\n",
    "projection['cluster'] = genre_data['cluster']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'genres'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                                  ('kmeans', KMeans(n_clusters=20,\n",
    "                                   verbose=False))\n",
    "                                 ], verbose=False)\n",
    "\n",
    "X = data.select_dtypes(np.number)\n",
    "number_cols = list(X.columns)\n",
    "song_cluster_pipeline.fit(X)\n",
    "song_cluster_labels = song_cluster_pipeline.predict(X)\n",
    "data['cluster_label'] = song_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Clusters with PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "song_embedding = pca_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
    "projection['title'] = data['name']\n",
    "projection['cluster'] = data['cluster_label']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spotipy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "\n",
    "# Replace 'YOUR_CLIENT_ID' and 'YOUR_CLIENT_SECRET' with your actual Spotify API credentials\n",
    "\n",
    "client_id = '8cd4598f52a34584b7577957a57b99af'\n",
    "client_secret = '86614e0eccbf4d2bb6d51a472fb202d4'\n",
    "# Check if the environment variables are set\n",
    "if not client_id or not client_secret:\n",
    "    raise ValueError(\"Spotify API credentials not found in environment variables. Please set SPOTIPY_CLIENT_ID and SPOTIPY_CLIENT_SECRET.\")\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id,\n",
    "                                                           client_secret=client_secret))\n",
    "\n",
    "def find_song(name, year):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "\n",
    "    # Handle potential errors when fetching audio features\n",
    "    try:\n",
    "        audio_features = sp.audio_features(track_id)[0]\n",
    "    except spotipy.exceptions.SpotifyException as e:\n",
    "        print(f\"Error fetching audio features for track {track_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['year'] = [year]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import difflib\n",
    "\n",
    "number_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    " 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n",
    "\n",
    "\n",
    "def get_song_data(song, spotify_data):\n",
    "    \n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) \n",
    "                                & (spotify_data['year'] == song['year'])].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song(song['name'], song['year'])\n",
    "        \n",
    "\n",
    "def get_mean_vector(song_list, spotify_data):\n",
    "    \n",
    "    song_vectors = []\n",
    "    \n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n",
    "            continue\n",
    "        song_vector = song_data[number_cols].values\n",
    "        song_vectors.append(song_vector)  \n",
    "    \n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)\n",
    "\n",
    "\n",
    "def flatten_dict_list(dict_list):\n",
    "    \n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n",
    "\n",
    "\n",
    "def recommend_songs( song_list, spotify_data, n_songs=10):\n",
    "    \n",
    "    metadata_cols = ['name', 'year', 'artists']\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "    \n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "    scaler = song_cluster_pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(spotify_data[number_cols])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n",
    "    return rec_songs[metadata_cols].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_songs([{'name': 'Come As You Are', 'year':1991},\n",
    "                {'name': 'Smells Like Teen Spirit', 'year': 1991},\n",
    "                {'name': 'Lithium', 'year': 1992},\n",
    "                {'name': 'All Apologies', 'year': 1993},\n",
    "                {'name': 'Stay Away', 'year': 1993}],  data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'data' is your DataFrame containing song information\n",
    "\n",
    "# Create a dictionary to store keyword associations with song titles\n",
    "keyword_associations = {\n",
    "    \"Forest\": [\"If I Were King Of The Forest - Extended Version\", \"Into The Forest Of Wild Beasts\"],  # Add relevant songs\n",
    "    \"Glacier\": [\"Glaciers of Ice (feat. Ghostface Killah & Masta Killa)\", \"Past Ice and Ice and Even More\"],  # Add relevant songs\n",
    "    \"Desert\": [\"Desert Places\", \"Night On The Desert\"],  # Add relevant songs\n",
    "    \"Coast\": [\"Pacific Coast Highway\", \"West Coast\"]  # Add relevant songs\n",
    "}\n",
    "\n",
    "def recommend_songs_by_keyword(keyword, spotify_data, n_songs=10):\n",
    "    if keyword in keyword_associations:\n",
    "        associated_songs = keyword_associations[keyword]\n",
    "        song_list = []\n",
    "        for song_name in associated_songs:\n",
    "            # Check if the song exists in the data DataFrame\n",
    "            if any(data['name'] == song_name):\n",
    "                year = data[data['name'] == song_name]['year'].values[0]\n",
    "                song_list.append({'name': song_name, 'year': year})\n",
    "            else:\n",
    "                print(f\"Warning: Song '{song_name}' not found in data DataFrame.\")\n",
    "        # Proceed with recommendations if song_list is not empty\n",
    "        if song_list:\n",
    "            return recommend_songs(song_list, spotify_data, n_songs)\n",
    "        else:\n",
    "            return \"No associated songs found in data DataFrame.\"\n",
    "    else:\n",
    "        return \"Keyword not found in associations.\"\n",
    "\n",
    "# Example usage\n",
    "recommendations = recommend_songs_by_keyword(predicted_label, data)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
